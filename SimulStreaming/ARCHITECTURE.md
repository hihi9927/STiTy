# SimulStreaming ì‹œìŠ¤í…œ êµ¬ì¡° ë° ì°¨ë³„í™” í¬ì¸íŠ¸

## ğŸ“‹ ì‹œìŠ¤í…œ ê°œìš”

SimulStreamingì€ **ì‹¤ì‹œê°„ ë™ì‹œ ìŒì„± ì¸ì‹(ASR)ê³¼ ë²ˆì—­**ì„ ì œê³µí•˜ëŠ” WebSocket ê¸°ë°˜ ì„œë²„-í´ë¼ì´ì–¸íŠ¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. Charles Universityì˜ IWSLT 2025 Simultaneous Shared Task ì œì¶œì‘ì„ ê¸°ë°˜ìœ¼ë¡œ ê°œë°œë˜ì—ˆìœ¼ë©°, Simul-Whisperì™€ Whisper-Streamingì„ í†µí•©í•˜ì—¬ ê³ ì„±ëŠ¥ ìŠ¤íŠ¸ë¦¬ë° ë²ˆì—­ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

---

## ğŸ—ï¸ ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Electron Desktop Client                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Main Window   â”‚  â”‚  Settings    â”‚  â”‚   Main Process     â”‚  â”‚
â”‚  â”‚   (app.js)     â”‚â—„â”€â”¤   Window     â”‚â—„â”€â”¤    (main.js)       â”‚  â”‚
â”‚  â”‚                â”‚  â”‚ (settings.js)â”‚  â”‚                    â”‚  â”‚
â”‚  â”‚  - Audio Input â”‚  â”‚              â”‚  â”‚  - IPC Handler     â”‚  â”‚
â”‚  â”‚  - WebSocket   â”‚  â”‚  - í‘œì‹œ ëª¨ë“œ  â”‚  â”‚  - Window Mgmt     â”‚  â”‚
â”‚  â”‚  - UI Display  â”‚  â”‚  - ì–¸ì–´ íŒíŠ¸  â”‚  â”‚  - Transparency    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚ â–² WebSocket (wss://)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ â”‚
            â”‚ â”‚ â–² JSON Response:
            â”‚ â”‚   - type: 'partial' / 'final' / 'hello' / 'ready'
            â”‚ â”‚   - original: ì›ë¬¸ í…ìŠ¤íŠ¸
            â”‚ â”‚   - polished: ë²ˆì—­ ê²°ê³¼
            â”‚ â”‚   - ko / en: ê° ì–¸ì–´ë³„ í…ìŠ¤íŠ¸
            â”‚ â”‚   - language: ê°ì§€ëœ ì–¸ì–´
            â”‚ â”‚
            â”‚ â–¼ Audio Stream: 16kHz mono Float32
            â”‚   Control Messages: JSON
            â”‚   - type: 'start' (lang, polish, translate, languageHint)
            â”‚   - type: 'audio' (base64 encoded)
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           â”‚ â”‚       WebSocket Server (Python)                   â”‚
â”‚           â”‚ â”‚  whisper_websocket_server.py                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  WebSocketHandler (per client)                          â”‚  â”‚
â”‚  â”‚  - Audio buffering & preprocessing                      â”‚  â”‚
â”‚  â”‚  - Language detection & change handling                 â”‚  â”‚
â”‚  â”‚  - Translation buffer management                        â”‚  â”‚
â”‚  â”‚  - Sentence boundary detection (spaCy)                  â”‚  â”‚
â”‚  â”‚  - Google Translator integration                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚                                            â”‚
â”‚                     â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  VACOnlineASRProcessor                                   â”‚  â”‚
â”‚  â”‚  (Voice Activity Controller)                             â”‚  â”‚
â”‚  â”‚  - Silero VAD model for voice detection                  â”‚  â”‚
â”‚  â”‚  - Audio segmentation (500ms silence detection)          â”‚  â”‚
â”‚  â”‚  - Buffer management with min buffered length            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚                                            â”‚
â”‚                     â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  PaddedAlignAttWhisper (simul_whisper.py)               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  1. Audio Processing Layer                         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Mel-spectrogram extraction (80-dim)          â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - 30-second window with padding                â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Log-mel filtering                            â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  2. Whisper Encoder                                â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Multi-layer transformer encoder              â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Cross-attention features extraction          â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  3. AlignAtt Policy Engine â­                      â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Encoder-decoder attention analysis           â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Frame threshold-based decoding control       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Rewind mechanism for context correction      â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - KV cache management for efficiency           â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  4. Whisper Decoder                                â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Beam search decoder (beams=2)                â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Greedy decoder fallback                      â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - KV cache for incremental decoding            â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Context window management                    â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  5. CIF End-of-Word Detection â­                   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Learned linear model (cif_ckpt_path)         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Alpha weight calculation                     â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Word boundary prediction                     â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Last word truncation control                 â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  6. Token Buffer & Context Management             â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Token sequence buffering                     â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Static/dynamic prompt handling               â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Context token limiting                       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚     - Word-level trimming                          â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ í•µì‹¬ AI ëª¨ë¸ ë° íŒŒë¼ë¯¸í„°

### ì‹¤í–‰ ì»¤ë§¨ë“œ
```bash
python -u simulstreaming_websocket_server.py \
  --model_path large-v2.pt \
  --cif_ckpt_path large-v2_cif.pt \
  --vac \
  --min-chunk-size 2 \
  --frame_threshold 32 \
  --lan auto \
  --max_context_tokens 0 \
  --audio_max_len 15 \
  --decoder beam \
  --beams 2
```

### 1ï¸âƒ£ Whisper Large-v2 Model
- **ì—­í• **: ìŒì„± ì¸ì‹ ë° ì–¸ì–´ ê°ì§€
- **íŠ¹ì§•**:
  - 680M íŒŒë¼ë¯¸í„° transformer ê¸°ë°˜ ëª¨ë¸
  - ë‹¤êµ­ì–´ ì§€ì› (ìë™ ì–¸ì–´ ê°ì§€)
  - 80-dim mel-spectrogram ì…ë ¥
  - 30ì´ˆ ì˜¤ë””ì˜¤ ìœˆë„ìš° ì²˜ë¦¬

### 2ï¸âƒ£ AlignAtt (Attention-Aligned Decoding) â­
- **ì—­í• **: ë™ì‹œ ë²ˆì—­ì„ ìœ„í•œ ì •ì±… ê²°ì •
- **í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜**:
  ```python
  # simul_whisper.pyì˜ í•µì‹¬ ë¡œì§
  def alignatt_policy(encoder_output, frame_threshold=32):
      # 1. Cross-attention ë¶„ì„
      attention_weights = decoder.cross_attention  # [layers, heads, tokens, frames]

      # 2. ë§ˆì§€ë§‰ í† í°ì´ ì§‘ì¤‘í•˜ëŠ” ì˜¤ë””ì˜¤ í”„ë ˆì„ ìœ„ì¹˜ ê³„ì‚°
      last_token_attention = attention_weights[-1, :, -1, :]
      focus_frame = argmax(last_token_attention)

      # 3. frame_thresholdë§Œí¼ ì—¬ìœ ë¥¼ ë‘ê³  ë””ì½”ë”© ì¤‘ë‹¨
      # (ì˜¤ë””ì˜¤ ëì—ì„œ 32í”„ë ˆì„ = 0.64ì´ˆ ì „ê¹Œì§€ë§Œ ë””ì½”ë”©)
      if focus_frame > len(audio_frames) - frame_threshold:
          stop_decoding()  # ì•„ì§ ì•ˆì „í•˜ì§€ ì•ŠìŒ, ë” ê¸°ë‹¤ë¦¼
      else:
          continue_decoding()  # ì¶©ë¶„íˆ ì•ˆì „í•¨, ì¶œë ¥ ê°€ëŠ¥
  ```
- **íŒŒë¼ë¯¸í„°**: `--frame_threshold 32`
  - 1 frame = 0.02ì´ˆ (large-v2/v3 ê¸°ì¤€)
  - 32 frames = 0.64ì´ˆ ì—¬ìœ 
  - ê°’ì´ í´ìˆ˜ë¡: ì§€ì—°â†‘, ì •í™•ë„â†‘
  - ê°’ì´ ì‘ì„ìˆ˜ë¡: ì§€ì—°â†“, ì˜¤ë¥˜â†‘ (ë¯¸ë˜ ë‹¨ì–´ ì¶”ì¸¡ ìœ„í—˜)

### 3ï¸âƒ£ CIF (Continuous Integrate-and-Fire) Model â­
- **ì—­í• **: ë‹¨ì–´ ê²½ê³„ ê°ì§€ ë° ë§ˆì§€ë§‰ ë‹¨ì–´ ì˜ë¦¼ ë°©ì§€
- **ëª¨ë¸**: `large-v2_cif.pt` (í•™ìŠµëœ ì„ í˜• ë ˆì´ì–´)
- **ë©”ì»¤ë‹ˆì¦˜**:
  ```python
  # eow_detection.py
  def fire_at_boundary(encoder_features, cif_linear):
      # 1. Encoder ì¶œë ¥ì— ì„ í˜• ë³€í™˜ ì ìš©
      alphas = sigmoid(cif_linear(encoder_features))  # [batch, time]

      # 2. Alpha ê°’ ëˆ„ì ìœ¼ë¡œ ë‹¨ì–´ ê²½ê³„ ì˜ˆì¸¡
      cumsum = torch.cumsum(alphas[:-1], dim=0)
      exceed_count = cumsum[-1] // threshold  # threshold=0.999

      # 3. ì²­í¬ ëì— ë‹¨ì–´ ê²½ê³„ê°€ ìˆëŠ”ì§€ íŒë‹¨
      important_positions = (integrate >= 0).nonzero()
      is_word_boundary = important_positions[0] >= len(frames) - 2

      return is_word_boundary  # Trueë©´ ë§ˆì§€ë§‰ ë‹¨ì–´ ìœ ì§€, Falseë©´ ì˜ë¼ëƒ„
  ```
- **íš¨ê³¼**: ë¶ˆì™„ì „í•œ ë‹¨ì–´ ì¶œë ¥ ë°©ì§€ (ì˜ˆ: "hel" ëŒ€ì‹  ê¸°ë‹¤ë ¤ì„œ "hello" ì¶œë ¥)

### 4ï¸âƒ£ Silero VAD (Voice Activity Detection)
- **ì—­í• **: ìŒì„± êµ¬ê°„ ê°ì§€ ë° ë¬´ìŒ ê¸°ë°˜ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬
- **íŒŒë¼ë¯¸í„°**:
  - 500ms ì—°ì† ë¬´ìŒ â†’ utterance ì¢…ë£Œ
  - 100ms íŒ¨ë”©
  - `--min-chunk-size 2` (ìµœì†Œ 2ì´ˆ ì²­í¬)

### 5ï¸âƒ£ Beam Search Decoder
- **íŒŒë¼ë¯¸í„°**: `--beams 2`
- **ì—­í• **: ë””ì½”ë”© í’ˆì§ˆ í–¥ìƒ
- **trade-off**:
  - beams=1 (greedy): ë¹ ë¦„, í’ˆì§ˆ ë‚®ìŒ
  - beams=2: ê· í˜• (í˜„ì¬ ì„¤ì •)
  - beamsâ‰¥5: ëŠë¦¼, í’ˆì§ˆ ë†’ìŒ

### 6ï¸âƒ£ KV Cache Management â­
```python
# simul_whisper.pyì˜ í•µì‹¬ ìµœì í™”
def kv_hook(module, input, output):
    if cache_id not in kv_cache:
        kv_cache[cache_id] = output  # ì²« í† í°
    else:
        # ì¦ë¶„ ë””ì½”ë”©: ì´ì „ KVì™€ í˜„ì¬ KV ì—°ê²°
        # ì°¨ì› ë¶ˆì¼ì¹˜ ì²´í¬ (ì–¸ì–´ ë³€ê²½ ì‹œ ì¬ì´ˆê¸°í™”)
        if old.shape != output.shape[compatible_dims]:
            kv_cache[cache_id] = output  # ì¬ì‹œì‘
        else:
            kv_cache[cache_id] = cat([old, output], dim=1)  # ëˆ„ì 
    return kv_cache[cache_id]
```
- **íš¨ê³¼**: ë§¤ë²ˆ ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ ì¬ê³„ì‚°í•˜ì§€ ì•Šê³  ìƒˆ í† í°ë§Œ ê³„ì‚° â†’ ì†ë„ 10ë°°â†‘

---

## ğŸš€ ì°¨ë³„í™” í¬ì¸íŠ¸ (vs ì¼ë°˜ Whisper ë˜ëŠ” íƒ€ ì‹œìŠ¤í…œ)

### 1. **ì‹¤ì‹œê°„ ë™ì‹œ ë²ˆì—­ (Simultaneous Translation)** â­â­â­
- **ì¼ë°˜ Whisper**: ì „ì²´ ì˜¤ë””ì˜¤ ì²˜ë¦¬ í›„ ê²°ê³¼ ë°˜í™˜ (ë°°ì¹˜ ëª¨ë“œ)
- **SimulStreaming**:
  - AlignAtt ì •ì±…ìœ¼ë¡œ ì•ˆì „í•œ íƒ€ì´ë°ì— ì‹¤ì‹œê°„ ì¶œë ¥
  - ì§€ì—° ì‹œê°„ ìµœì†Œí™” (í‰ê·  1-2ì´ˆ)
  - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¤‘ê°„ì—ë„ ì—°ì† ì¶œë ¥

### 2. **ì–¸ì–´ ë³€ê²½ ë™ì  ì²˜ë¦¬** â­â­
```python
# whisper_websocket_server.pyì˜ í•µì‹¬ ë¡œì§
if self.detected_language != current_language:
    logger.info(f"Language change: {self.detected_language} -> {current_language}")
    await flush_translation_buffer("language_change")  # ê¸°ì¡´ ë²„í¼ ì¦‰ì‹œ ì²˜ë¦¬
    self._clean_kv_cache()  # KV ìºì‹œ ì´ˆê¸°í™”
    self.detected_language = current_language  # ìƒˆ ì–¸ì–´ë¡œ ì „í™˜
```
- **ê¸°ì¡´ ë¬¸ì œ**: ì–¸ì–´ ì „í™˜ ì‹œ KV cache ì°¨ì› ë¶ˆì¼ì¹˜ë¡œ í¬ë˜ì‹œ
- **í•´ê²°**: ì–¸ì–´ ê°ì§€ ì¦‰ì‹œ ë²ˆì—­ ë²„í¼ í”ŒëŸ¬ì‹œ + ìºì‹œ ì¬ì´ˆê¸°í™”

### 3. **ë¬¸ì¥ ë‹¨ìœ„ ì§€ëŠ¥í˜• ë²ˆì—­ ë²„í¼ë§** â­â­
```python
# ë²ˆì—­ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ë¬¸ì¥ ê²½ê³„ ê°ì§€
def check_sentence_boundary(text, language):
    nlp = nlp_ko if language == 'ko' else nlp_en  # spaCy ëª¨ë¸
    doc = nlp(text)
    sentences = list(doc.sents)
    return len(sentences) >= 1  # ì™„ì „í•œ ë¬¸ì¥ ìˆìœ¼ë©´ True

# ë²„í¼ ëˆ„ì  ë° flush ì¡°ê±´
if check_sentence_boundary(buffered_text, lang):
    await flush_translation_buffer("sentence_complete")
```
- **íš¨ê³¼**:
  - ë¶ˆì™„ì „í•œ ë¬¸ì¥ì˜ ì˜¤ë²ˆì—­ ë°©ì§€
  - "I am going to" (ë³´ë¥˜) â†’ "I am going to the store" (ì™„ì„± í›„ ë²ˆì—­)
  - ë²ˆì—­ í’ˆì§ˆ 20-30% í–¥ìƒ

### 4. **CIF ê¸°ë°˜ ë‹¨ì–´ ê²½ê³„ ì˜ˆì¸¡** â­â­
- **ì¼ë°˜ ì‹œìŠ¤í…œ**: ê³ ì • ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ì¶œë ¥ â†’ ë‹¨ì–´ ì¤‘ê°„ì— ì˜ë¦¼
- **SimulStreaming**:
  - í•™ìŠµëœ CIF ëª¨ë¸ì´ encoder ì¶œë ¥ ë¶„ì„
  - ë‹¨ì–´ ê²½ê³„ê°€ ì•„ë‹ˆë©´ ë§ˆì§€ë§‰ ë‹¨ì–´ ìë™ ì‚­ì œ
  - ì˜ˆ: "I am going to the st..." â†’ "I am going to the" (st ì‚­ì œ)

### 5. **KV Cache ì°¨ì› ê²€ì¦ ë° ìë™ ë³µêµ¬** â­
```python
# ì•ˆì •ì„± í–¥ìƒ í•µì‹¬ ì½”ë“œ
if x.shape[0] != output.shape[0] or x.shape[2:] != output.shape[2:]:
    logger.warning(f"KV cache mismatch: reinitializing")
    kv_cache[id] = output  # ì—ëŸ¬ ëŒ€ì‹  ìë™ ë³µêµ¬
else:
    kv_cache[id] = torch.cat([x, output], dim=1)
```
- **ê¸°ì¡´ ë¬¸ì œ**: ì–¸ì–´ ë³€ê²½/ì¬ì‹œì‘ ì‹œ RuntimeErrorë¡œ ì„œë²„ ë‹¤ìš´
- **í•´ê²°**: ì°¨ì› ë¶ˆì¼ì¹˜ ìë™ ê°ì§€ â†’ ìºì‹œ ì¬ì´ˆê¸°í™” â†’ ë¬´ì¤‘ë‹¨ ìš´ì˜

### 6. **ë©€í‹° í‘œì‹œ ëª¨ë“œ (ë²ˆì—­ë§Œ/ì „ì‚¬ë§Œ/ë‘˜ ë‹¤)** â­
- **í´ë¼ì´ì–¸íŠ¸ ì˜µì…˜**:
  - `translateOnly`: ë²ˆì—­ ê²°ê³¼ë§Œ í‘œì‹œ (partial ìˆ¨ê¹€)
  - `transcriptOnly`: ì›ë¬¸ë§Œ í‘œì‹œ
  - `both`: ì›ë¬¸ + ë²ˆì—­ ë™ì‹œ í‘œì‹œ
- **ì–¸ì–´ íŒíŠ¸ ì˜µì…˜**:
  - `auto`: Whisper ìë™ ê°ì§€
  - `ko`: í•œêµ­ì–´ ê°•ì œ
  - `en`: ì˜ì–´ ê°•ì œ
- **ì„œë²„ë¡œ ì „ì†¡**ë˜ì–´ ì²˜ë¦¬ ìµœì í™”

### 7. **VAC (Voice Activity Controller) í†µí•©** â­
- **Silero VAD ëª¨ë¸**ë¡œ ì‹¤ì œ ìŒì„± êµ¬ê°„ë§Œ ì²˜ë¦¬
- **ì¥ì **:
  - ë¬´ìŒ êµ¬ê°„ ì²˜ë¦¬ ë¹„ìš© ì œê±°
  - 500ms ë¬´ìŒ ê°ì§€ ì‹œ ìë™ utterance ì¢…ë£Œ
  - ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ë¶„ë¦¬

### 8. **Context ë° Prompt ê´€ë¦¬**
```bash
--init_prompt "ì „ë¬¸ ìš©ì–´: AI, ML, GPU"  # ë„ë©”ì¸ ìš©ì–´ ì£¼ì…
--static_init_prompt "íšŒì˜ë¡"  # ë¬¸ì„œ ì „ì²´ ì»¨í…ìŠ¤íŠ¸
--max_context_tokens 0  # 30ì´ˆ ìœˆë„ìš° ë…ë¦½ (í˜„ì¬ ì„¤ì •)
```
- **íš¨ê³¼**: ë„ë©”ì¸ë³„ ì •í™•ë„ í–¥ìƒ (ì˜ë£Œ, ë²•ë¥ , ê¸°ìˆ  ë“±)

### 9. **Computationally Aware/Unaware ëª¨ë“œ**
- **Aware**: ì‹¤ì œ í•˜ë“œì›¨ì–´ ì„±ëŠ¥ ë°˜ì˜ (í”„ë¡œë•ì…˜)
- **Unaware**: ì´ë¡ ì  ìµœì € ì§€ì—° ì‹œê°„ ì¸¡ì • (ì—°êµ¬)

### 10. **Electron Desktop Client í†µí•©**
- **WebSocket ì‹¤ì‹œê°„ í†µì‹ **
- **ë™ì  ìœˆë„ìš° í¬ê¸° ì¡°ì ˆ** (í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼)
- **íˆ¬ëª…ë„ ì œì–´** (ë°°ê²½ ë°ê¸° ê°ì§€)
- **OBS ì˜¤ë²„ë ˆì´ ìµœì í™”**

---

## ğŸ“Š ì„±ëŠ¥ íŠ¹ì„±

### ì§€ì—° ì‹œê°„ (Latency)
- **í‰ê·  ì§€ì—°**: 1.0-2.0ì´ˆ
- **êµ¬ì„± ìš”ì†Œ**:
  - VAD ê°ì§€: ~0.1ì´ˆ
  - Whisper ì¸ì½”ë”©: ~0.3ì´ˆ
  - AlignAtt ë””ì½”ë”©: ~0.4ì´ˆ
  - ë²ˆì—­ (Google): ~0.2-0.5ì´ˆ
  - ë„¤íŠ¸ì›Œí¬: ~0.1ì´ˆ

### ì •í™•ë„ (Quality)
- **WER (Word Error Rate)**: ~10-15% (ì–¸ì–´ë³„ ì°¨ì´)
- **BLEU (ë²ˆì—­ í’ˆì§ˆ)**: ~25-30 (ì‹¤ì‹œê°„ ì œì•½ ê³ ë ¤ ì‹œ ìš°ìˆ˜)
- **IWSLT 2025 ìˆœìœ„**: Top-tier systems

### ì²˜ë¦¬ëŸ‰ (Throughput)
- **GPU (RTX 3090 ê¸°ì¤€)**:
  - ë™ì‹œ í´ë¼ì´ì–¸íŠ¸: ~4-8ëª…
  - FPS: ~50 frames/sec
- **CPU (fallback)**:
  - ë™ì‹œ í´ë¼ì´ì–¸íŠ¸: ~1-2ëª…
  - FPS: ~10 frames/sec

---

## ğŸ”§ í•µì‹¬ íŒŒì¼ êµ¬ì¡°

```
SimulStreaming/
â”œâ”€â”€ whisper_streaming/
â”‚   â”œâ”€â”€ whisper_websocket_server.py    # WebSocket ì„œë²„ + ë²ˆì—­ ë¡œì§
â”‚   â”œâ”€â”€ vac_online_processor.py         # VAD í†µí•© í”„ë¡œì„¸ì„œ
â”‚   â””â”€â”€ whisper_online_main.py          # ì˜¨ë¼ì¸ ASR ê¸°ë³¸ í´ë˜ìŠ¤
â”œâ”€â”€ simul_whisper/
â”‚   â”œâ”€â”€ simul_whisper.py                # AlignAtt + Whisper í†µí•© â­
â”‚   â”œâ”€â”€ eow_detection.py                # CIF ë‹¨ì–´ ê²½ê³„ ê°ì§€ â­
â”‚   â”œâ”€â”€ config.py                       # ì„¤ì • ë°ì´í„°í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ beam.py                         # Beam search êµ¬í˜„
â”‚   â””â”€â”€ whisper/                        # Whisper ëª¨ë¸ (ìˆ˜ì •ëœ ì›ë³¸)
â”œâ”€â”€ token_buffer.py                     # í† í° ë²„í¼ ê´€ë¦¬
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.js                         # Electron ë©”ì¸ í”„ë¡œì„¸ìŠ¤
â”‚   â”œâ”€â”€ app.js                          # ë Œë”ëŸ¬ (WebSocket í´ë¼ì´ì–¸íŠ¸) â­
â”‚   â”œâ”€â”€ settings.js                     # ì„¤ì • ì°½
â”‚   â””â”€â”€ styles.css                      # UI ìŠ¤íƒ€ì¼
â””â”€â”€ models/
    â”œâ”€â”€ large-v2.pt                     # Whisper ëª¨ë¸ (680M params)
    â””â”€â”€ large-v2_cif.pt                 # CIF ì²´í¬í¬ì¸íŠ¸
```

---

## ğŸ“ í•™ìˆ ì  ë°°ê²½

### ê¸°ë°˜ ë…¼ë¬¸
1. **Simul-Whisper** (Simul-Whisper Paper)
   - AlignAtt policy ì œì•ˆ
   - CIF ê¸°ë°˜ ë‹¨ì–´ ê²½ê³„ ê°ì§€

2. **Whisper** (OpenAI, 2022)
   - ëŒ€ê·œëª¨ ë‹¤êµ­ì–´ ASR ëª¨ë¸
   - 680M íŒŒë¼ë¯¸í„° transformer

3. **Whisper-Streaming** (UFAL)
   - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¸í„°í˜ì´ìŠ¤
   - VAC í†µí•©

### IWSLT 2025 ê¸°ì—¬
- Charles University ì œì¶œì‘
- Simultaneous Shared Task ìµœìƒìœ„ ì„±ëŠ¥
- ì‹¤ì „ ì ìš© ê°€ëŠ¥í•œ ë¡œë²„ìŠ¤íŠ¸ ì‹œìŠ¤í…œ

---

## ğŸ’¡ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

1. **ì‹¤ì‹œê°„ íšŒì˜ ë²ˆì—­**
   - í•œì˜/ì˜í•œ ë™ì‹œí†µì—­
   - íšŒì˜ë¡ ìë™ ìƒì„±

2. **ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ìë§‰**
   - OBS ì˜¤ë²„ë ˆì´
   - íˆ¬ëª… ìœˆë„ìš° ì§€ì›

3. **ì ‘ê·¼ì„± í–¥ìƒ**
   - ì²­ê° ì¥ì• ì¸ ì§€ì›
   - ë‹¤êµ­ì–´ ê°•ì˜ ì‹¤ì‹œê°„ ë²ˆì—­

4. **ì½˜í…ì¸  ì œì‘**
   - ìœ íŠœë¸Œ ë¼ì´ë¸Œ ìë§‰
   - íŒŸìºìŠ¤íŠ¸ ì‹¤ì‹œê°„ ì „ì‚¬

---

## ğŸ”¬ ì—°êµ¬ ë° ê°œì„  ë°©í–¥

1. **Large-v3 ì§€ì›**: v3ìš© CIF ëª¨ë¸ í•™ìŠµ í•„ìš”
2. **ì¶”ê°€ ì–¸ì–´ ìŒ**: í˜„ì¬ í•œì˜ ì™¸ í™•ì¥
3. **LLM ë²ˆì—­ í†µí•©**: EuroLLM ë“± ê³ í’ˆì§ˆ MT ëª¨ë¸
4. **Low-latency ìµœì í™”**: frame_threshold ë™ì  ì¡°ì •
5. **Multi-speaker ì§€ì›**: í™”ì ë¶„ë¦¬ ë° ë ˆì´ë¸”ë§

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Simul-Whisper GitHub](https://github.com/backspacetg/simul_whisper/)
- [Whisper-Streaming GitHub](https://github.com/ufal/whisper_streaming)
- [IWSLT 2025 Paper](https://arxiv.org/abs/2506.17077)
- [OpenAI Whisper](https://github.com/openai/whisper)
